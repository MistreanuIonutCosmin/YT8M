{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15a5f5c8-3fdc-4693-919a-2fc9de2ecee2",
    "_uuid": "22217d65c9bfadd0e948a49b74a7ec75cba4437f"
   },
   "source": [
    "## This notebook explores the data (TFRecord format) using a subsample of the YouTube-8M video level.\n",
    "## To work with the entire dataset, please refer to the Starter code on the [YouTube-8M github repo](https://github.com/google/youtube-8m)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd \n",
    "\n",
    "#Loading libraries & datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "# Input data files should be available in the \"/input/\" directory.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import youtube_dl\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function collects the data provided by youtube-dl, such as rendition tables, number of views, etc.\n",
    "def get_metadata(video_id: str) -> str or None:\n",
    "    url = 'https://www.youtube.com/watch?v=' + video_id\n",
    "    ydl = youtube_dl.YoutubeDL({'outtmpl': '%(id)s%(ext)s'})\n",
    "    try:\n",
    "        with ydl:\n",
    "            result = ydl.extract_info(url, download=False)\n",
    "            return result\n",
    "    except youtube_dl.utils.DownloadError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For privacy reasons the video IDs in the dataset were provided with a codification. \n",
    "# Instructions and further information are available here:\n",
    "#      https://research.google.com/youtube8m/video_id_conversion.html\n",
    "def get_real_id(random_id: str) -> str:\n",
    "    url = 'http://data.yt8m.org/2/j/i/{}/{}.js'.format(random_id[0:2], random_id)\n",
    "    request = urlopen(url).read()\n",
    "    real_id = request.decode()\n",
    "    return real_id[real_id.find(',') + 2:real_id.find(')') - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need this function to filter out the fields of metadata we won't be using about each video\n",
    "def without_keys(d):\n",
    "    return {x: d[x] for x in d if x in wanted_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the TensorFlow records\n",
    "\n",
    "These records are organized by chunks or \"shards\" in the YT8M website. \n",
    "Instruction on how to get them is available here: https://research.google.com/youtube8m/download.html\n",
    "As it takes almost 96GB of our valuable hard disk, we have only ran experiments over three of them for this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f22c36cf-f788-4edc-9a88-32c116fa4cb8",
    "_uuid": "d1656e711254f02e2479e2f95704e3dd42949607"
   },
   "outputs": [],
   "source": [
    "# The path to the TensorFlow record\n",
    "video_lvl_record = \"input/train00.tfrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d80e50b4-692b-480d-a3fd-d59cf226de19",
    "_uuid": "8bd33285e392f106994effc1a46644d073dcc5fc"
   },
   "source": [
    "## Iterate the records to obtain labels in the video level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7b19d838-f9db-4e22-8420-16b0d93f16fe",
    "_uuid": "16a62102bef4da3c6f5de8176267f7a5b0e74776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] eguZ69v_vlQ: Downloading webpage\n",
      "[youtube] eguZ69v_vlQ: Downloading video info webpage\n",
      "[youtube] eguZ69v_vlQ: Downloading MPD manifest\n",
      "[youtube] eguZ69v_vlQ: Downloading MPD manifest\n",
      "[youtube] ER9Hdp04tWs: Downloading webpage\n",
      "[youtube] ER9Hdp04tWs: Downloading video info webpage\n",
      "[youtube] ETF2-Zz3J18: Downloading webpage\n",
      "[youtube] ETF2-Zz3J18: Downloading video info webpage\n",
      "[youtube] jtvbLq9bYRc: Downloading webpage\n",
      "[youtube] jtvbLq9bYRc: Downloading video info webpage\n",
      "[youtube] 6BPXQMxdHog: Downloading webpage\n",
      "[youtube] 6BPXQMxdHog: Downloading video info webpage\n",
      "[youtube] -j989rqetQE: Downloading webpage\n",
      "[youtube] -j989rqetQE: Downloading video info webpage\n",
      "[youtube] F-4h2WwVr3g: Downloading webpage\n",
      "[youtube] F-4h2WwVr3g: Downloading video info webpage\n",
      "[youtube] UZt7rP0poxs: Downloading webpage\n",
      "[youtube] UZt7rP0poxs: Downloading video info webpage\n",
      "[youtube] UZt7rP0poxs: Downloading MPD manifest\n",
      "[youtube] UZt7rP0poxs: Downloading MPD manifest\n",
      "[youtube] kGFuNGexHJY: Downloading webpage\n",
      "[youtube] kGFuNGexHJY: Downloading video info webpage\n",
      "[youtube] kGFuNGexHJY: Downloading MPD manifest\n",
      "[youtube] kGFuNGexHJY: Downloading MPD manifest\n",
      "[youtube] kKZBuy8kaj8: Downloading webpage\n",
      "[youtube] kKZBuy8kaj8: Downloading video info webpage\n",
      "[youtube] kLVJJvEQN44: Downloading webpage\n",
      "[youtube] kLVJJvEQN44: Downloading video info webpage\n",
      "[youtube] GLqhiVWGm8Q: Downloading webpage\n",
      "[youtube] GLqhiVWGm8Q: Downloading video info webpage\n",
      "[youtube] -QUa6WgjDqc: Downloading webpage\n",
      "[youtube] -QUa6WgjDqc: Downloading video info webpage\n",
      "[youtube] -QUa6WgjDqc: Downloading MPD manifest\n",
      "[youtube] -QM5ooctj0w: Downloading webpage\n",
      "[youtube] -QM5ooctj0w: Downloading video info webpage\n",
      "[youtube] -QM5ooctj0w: Downloading MPD manifest\n",
      "[youtube] -QM5ooctj0w: Downloading MPD manifest\n",
      "[youtube] wh6bhC_fXNU: Downloading webpage\n",
      "[youtube] wh6bhC_fXNU: Downloading video info webpage\n",
      "[youtube] wh6bhC_fXNU: Downloading MPD manifest\n",
      "[youtube] wo-Rbbuy8rk: Downloading webpage\n",
      "[youtube] wo-Rbbuy8rk: Downloading video info webpage\n",
      "[youtube] mZprGYcQ-HI: Downloading webpage\n",
      "[youtube] mZprGYcQ-HI: Downloading video info webpage\n"
     ]
    }
   ],
   "source": [
    "vid_ids = []\n",
    "labels = []\n",
    "\n",
    "data = pd.DataFrame()\n",
    "wanted_data = ['format', 'quality']\n",
    "\n",
    "# Iterate the contents of the TensorFlow record\n",
    "for example in tf.python_io.tf_record_iterator(video_lvl_record):\n",
    "    \n",
    "    # A TensoFlow Example is a mostly-normalized data format for storing data for\n",
    "    # training and inference.  It contains a key-value store (features); where\n",
    "    # each key (string) maps to a Feature message (which is oneof packed BytesList,\n",
    "    # FloatList, or Int64List). Features for this data set are:\n",
    "    #     -id\n",
    "    #     -labels\n",
    "    #     -mean_audio\n",
    "    #     -mean_rgb\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    \n",
    "    # Once we have the structured data, we can extract the relevant features (id and labels)\n",
    "    vid_ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "    pseudo_id = tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n",
    "    labels = tf_example.features.feature['labels'].int64_list.value\n",
    "    audio = tf_example.features.feature['mean_rgb'].int64_list.value\n",
    "    \n",
    "    # The id provided from the TensoFlow example needs some processing in order to build a valid link to a \n",
    "    # YouTube video\n",
    "    real_id = get_real_id(pseudo_id)\n",
    "    \n",
    "    # Get the youtube-dl valuable metadata\n",
    "    data_video = get_metadata(real_id)\n",
    "    \n",
    "    \n",
    "    if data_video:\n",
    "        \n",
    "        # We are interested in expanding the labels information with features such as title, \n",
    "        # creator, number of views and duration\n",
    "        title = data_video['title']\n",
    "        creator = data_video['creator']\n",
    "        view_count = data_video['view_count']\n",
    "        duration = data_video['duration']\n",
    "        \n",
    "        # youtube-dl library supplies data regarding formats mixed for both audio and video.\n",
    "        # We are only interested in mp4 inputs, so we need to separate\n",
    "        formats_dict = []\n",
    "        for format_type in data_video['formats']:\n",
    "            try:\n",
    "                if(format_type['ext'] == 'mp4'):\n",
    "                    formats_dict.append({format_type['format']:format_type['tbr']})\n",
    "            except:\n",
    "                e = sys.exc_info()\n",
    "        #       print('error:', e)\n",
    "                \n",
    "    # Collect the data in the dataframe\n",
    "    data = data.append({'id': real_id, \n",
    "                        'ladder': formats_dict, \n",
    "                        'title': title, \n",
    "                        'creator': creator, \n",
    "                        'views': view_count,\n",
    "                        'duration': duration,\n",
    "                        'labels': labels},\n",
    "                        ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data before using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the data for others to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('yt8m_data-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
